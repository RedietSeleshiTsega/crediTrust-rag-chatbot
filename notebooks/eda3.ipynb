{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f60d0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de9df9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.read_index(\"vector_store/faiss_index.index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a27f178a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"vector_store/documents.pkl\", \"rb\") as f:\n",
    "    documents = pickle.load(f)\n",
    "\n",
    "with open(\"vector_store/metadata.pkl\", \"rb\") as f:\n",
    "    metadata = pickle.load(f)\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5df815d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_chunks(question, k=5):\n",
    "    \"\"\"Embed question and retrieve top-k relevant chunks.\"\"\"\n",
    "    question_embedding = model.encode([question])\n",
    "    _, indices = index.search(np.array(question_embedding), k)\n",
    "    results = [documents[i] for i in indices[0]]\n",
    "    result_meta = [metadata[i] for i in indices[0]]\n",
    "    return results, result_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7514a659",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(context_chunks, question):\n",
    "    context = \"\\n---\\n\".join(context_chunks)\n",
    "    prompt = f\"\"\"You are a financial analyst assistant for CrediTrust. Your task is to answer questions about customer complaints.\n",
    "\n",
    "Use only the information from the retrieved complaint excerpts below.\n",
    "\n",
    "If the context does not contain the answer, say: 'I don't have enough information to answer that.'\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abf0081f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=r\"C:\\Users\\bless\\OneDrive\\Desktop\\week _6\\crediTrust-rag-chatbot\\models\\flan-t5-base\",  # local path\n",
    "    tokenizer=r\"C:\\Users\\bless\\OneDrive\\Desktop\\week _6\\crediTrust-rag-chatbot\\models\\flan-t5-base\",\n",
    "    device=-1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35d4acc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(question):\n",
    "    \n",
    "    answer = \"This is a sample answer to: \" + question\n",
    "    sources = [\"doc1\", \"doc2\"]\n",
    "    metadata = {\"source_type\": \"demo\"}\n",
    "\n",
    "    return answer, sources, metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52aa6cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a sample answer to: Why are customers unhappy with BNPL?\n"
     ]
    }
   ],
   "source": [
    "question = \"Why are customers unhappy with BNPL?\"\n",
    "answer, sources, metadata = generate_answer(question)\n",
    "print(answer)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
